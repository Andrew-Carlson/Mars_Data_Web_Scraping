{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b86984c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup as soup\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a2ca5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up and create an instance of splinter (prep automated browser and specify that it is chrome)\n",
    "\n",
    "executable_path = {'executable_path': ChromeDriverManager().install()}\n",
    "\n",
    "# **executable_path is unpacking the dictionary we've stored the path in\n",
    "# headless=False means that all of the browser's actions will be displayed in a Chrome window so we can see them.\n",
    "\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e93f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visit the mars nasa news site\n",
    "\n",
    "url = 'https://redplanetscience.com'\n",
    "\n",
    "browser.visit(url)\n",
    "\n",
    "# Optional delay for loading the page\n",
    "\n",
    "browser.is_element_present_by_css('div.list_text', wait_time=1) \n",
    "\n",
    "# more info: https://splinter.readthedocs.io/en/latest/matchers.html\n",
    "# the .is_element_present_by_css function checks for certain elements that are argued\n",
    "# div.list_text is the html tag and class for the article titles on the webpage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffe0a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  returns True since element is present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771bcee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an HTML object and parse with bs4\n",
    "\n",
    "html = browser.html\n",
    "\n",
    "news_soup = soup(html, 'html.parser')\n",
    "\n",
    "# assigned slide_elem as the variable to look for the <div /> tag \n",
    "# and its descendent (the other tags within the <div /> element)\n",
    " \n",
    "slide_elem = news_soup.select_one('div.list_text') # select_one() finds only the first tag that matches a selector\n",
    "\n",
    "# the period is used for assigning classes in div.list_text\n",
    "\n",
    "slide_elem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a717c75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the title of the article in the div tag of class list_text\n",
    "# The output should be the HTML containing the content title and anything else nested inside of that <div />.\n",
    "slide_elem.find('div', class_='content_title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f3b3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the parent element to find the first `a` tag and save it as `news_title`\n",
    "\n",
    "news_title = slide_elem.find('div', class_= 'content_title').get_text()\n",
    "\n",
    "news_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf0ee35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are two methods used to find tags and attributes with BeautifulSoup:\n",
    "# .find() is used when we want only the first class and attribute we've specified.\n",
    "# .find_all() is used when we want to retrieve all of the tags and attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b839b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the parent element to find the paragraph text\n",
    "\n",
    "news_p = slide_elem.find('div', class_='article_teaser_body').get_text()\n",
    "\n",
    "news_p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d928da",
   "metadata": {},
   "source": [
    "### Featured Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cdafcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visit URL\n",
    "url = 'https://spaceimages-mars.com'\n",
    "browser.visit(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4accb42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find and click the full image button on the webpage\n",
    "\n",
    "full_image_elem = browser.find_by_tag('button')[1]\n",
    "\n",
    "full_image_elem.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3496046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the resulting html with soup \n",
    "\n",
    "html = browser.html\n",
    "\n",
    "img_soup = soup(html, 'html.parser')\n",
    "\n",
    "img_soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2ff776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the relative image url\n",
    "\n",
    "img_url_rel = img_soup.find('img', class_ = 'fancybox-image').get('src')\n",
    "\n",
    "img_url_rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014196c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an absolute url that works. The above url is only partial\n",
    "\n",
    "img_url = f'https://spaceimages-mars.com/{img_url_rel}'\n",
    "\n",
    "img_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0267fe42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We're using an f-string for this print statement because it's a cleaner way to create print statements; \n",
    "# they're also evaluated at run-time. This means that it, \n",
    "# and the variable it holds, doesn't exist until the code is executed and the values are not constant. \n",
    "# This works well for our scraping app because the data we're scraping is live and will be updated frequently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51bc50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use pandas read_html() function to return a list of all the tables present  in the html code of the website.\n",
    "# using the index [0] will return the first table found in the html. \n",
    "\n",
    "df = pd.read_html('https://galaxyfacts-mars.com/')[0]\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9675a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create column names for df\n",
    "df.columns=['description', 'Mars', 'Earth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772b558e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5e9b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# .set_index() function, we're turning the Description column into the DataFrame's index. \n",
    "# inplace=True means that the updated index will remain in place without having to reassign the DataFrame to a new variable.\n",
    "df.set_index('description', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31fef20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e627f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use pandas to convert dataframe into its html code:\n",
    "\n",
    "df.to_html()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31d72c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# notice that it is an html table element with the tag <table /> along with many nested elements\n",
    "# the dataframe can be put into a web application since it is made up of this html code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8838feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# end the automated browsing session.\n",
    "# this is very important because the automated browser would otherwise not know when to shutdown\n",
    "# the browser will therefore continure to listen for instructions and this can put a strain on the computer's memory or battery.\n",
    "\n",
    "browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d6794f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Live sites are a great resource for fresh data, but the layout of the site may be updated or otherwise changed. \n",
    "# When this happens it's likely the scraping code will break and need to be reviewed and updated to be used again.\n",
    "# For example, an image may suddenly become embedded within an inaccessible block of code because the developers \n",
    "# switched to a new JavaScript library. \n",
    "# It's not uncommon to revise code to find workarounds or even look for a different, scraping-friendly site all together."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
